# Multi label comment toxicity model
This repository contains the code and resources for a multi-label comment toxicity classification model built using TensorFlow. The model enables the classification of comments into six categories: identity-hate, threat, obscene, toxic, insult, and severe-toxic. The implementation employs advanced Natural Language Processing (NLP) methodologies, including vectorization and word embeddings, to extract meaningful features from comments.

## Dataset
The model is trained on a Kaggle dataset, which includes labeled comments for multi-label toxicity classification. The dataset provides a valuable resource for training and evaluating the model's performance.\

[Source](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)
